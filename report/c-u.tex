\label{sec:c-u}

The representation of meaning (the result of semantic parsing) depends on each system and need not to be unified. Similar to "Target Meaning Representation" of \cite{Clarke:2010:DSP:1870568.1870571}, in our system, the format of "Computer-understandable language" is the composition of pre-defined functions. Each function has only one argument. For example, $longest(river(stateId("colorado")))$ is a CUL sentence, being a result of semantic parsing for
"{\fontencoding{T5}\selectfont con s\ocircumflex ng d\`ai nh\'\acircumflex t ch\h{a}y qua colorado l\`a g\`i?}" ("What is the longest river run through colarado ?"). There are two steps of building a CUL sentence from a natural language sentence. The first one is finding the mapping between each token in natural language sentence to a function. Next, we need to compose the mapped functions into a complete logical form.

\section{Predefined Functions}
As mentioned, our CUL uses a set of functions in order to represent and process the meaning of each input sentence. Each function has only one parameter and returns a value of some type. In addition, a function should not accept any argument, but only some suitable typed one. For this reason, types of functions are supposed to be configured. For instance, $length$ function receives an argument of type $River$ and return an $Integer$ value. The list of functions and their information are required to be defined in a text file. This way of configuration makes our system flexible because if we want to change the data, changing the functions configuration file is enough.

\section{Token - Function mapping}
In Natural language processing, there often is a pre-process phase, in which a list of tokens is generated from the input sentence. This phase is also called tokenization. Token is an element that has some meanings. For example, "New Mexico" should be one token instead of being divided into two tokens. This is because "New Mexico" is the name of a city, we can not separate two words as different tokens. An other instance is "{\fontencoding{T5}\selectfont ti\h\ecircumflex u bang}" in Vietnamese. This word means "state". If we break it into "{\fontencoding{T5}\selectfont ti\h\ecircumflex u}" and "bang" as tokens, the original meaning is not preserved. Currently, there are a lot of works have dealed with tokenization for Vietnamese with high accuracies such as ... (need citation here).

In our system, we assume that tokenization is provided by some other tools. Our accepted inputs are tokenized sentences. For example, "{\fontencoding{T5}\selectfont con s\ocircumflex ng, d\`ai nh\'\acircumflex t, ch\h{a}y, qua, colorado, l\`a, g\`i, ?}" is the accepted input, being translated into English as "What, is, the, longest, river, run, through, colarado, ?". Each token are supposed to be aligned with one function from the predefined ones. In the currently considered example, "{\fontencoding{T5}\selectfont con s\ocircumflex ng", "d\`ai nh\'\acircumflex t" and "colorado"} are mapped to $river$, $longest$ and $stateId$ functions respectively. 

\section{Function - Function composition}
When we have the alignment between tokens and functions, we need to make a final composition of the chosen functions. A function $f1$ could be composed with a function $f2$, i.e $f1(f2)$ is the result of composition, if returned type of $f2$ should agree with the argument type of $f1$. This is the reason why our system requires types of functions to be described in the configuration file. In previously mentioned example, $longest$ is composed with $river$; $river$ is composed with $stateId$. This leads to the final CUL sentence of the form $longest(river(stateId("colorado")))$.